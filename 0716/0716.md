# 4.1 資料預處理
資料預處理是機器學習流程中的重要步驟，透過不同的預處理策略可以將原始的數據轉換成更適合進行分析的格式。在本研究中，我們主要採用四種預處理方法，包括靜態校正、卡爾曼濾波器、正規化以及降採樣。

## 4.1.1 靜態校正
在數據處理過程中，靜態校正是用於消除傳感器固有的系統誤差。這些誤差通常在製造過程中形成，並在整個傳感器壽命中保持不變。通過減少這些誤差，我們可以得到更準確的傳感器讀數。

## 4.1.2 卡爾曼濾波器
卡爾曼濾波器是一種優化技術，用於消除測量數據中的隨機噪聲。這種技術特別適用於含有不確定性或誤差的數據。透過卡爾曼濾波器，我們可以提高數據的準確性和一致性，從而得到更好的機器學習結果。

## 4.1.3 正規化
正規化是一種將數據轉換成具有一致範數的處理方法。這種方法可以消除數據範疇間的不一致性，從而使得不同的特徵能在同一的比例尺度下進行比較。在本研究中，我們使用正規化以確保所有的特徵在模型訓練過程中具有相同的重要性。

## 4.1.4 降採樣
降採樣是一種將數據的採樣頻率降低的方法，其主要目的是減少數據量和計算負荷。在本研究中，我們採用降採樣以減少對計算資源的需求，同時也可以避免在數據過度密集的情況下出現的過擬合現象。

## 4.1.5 預處理消融實驗
為了探討各種預處理策略對最終結果的影響，我們設計了一系列的消融實驗。在每個消融實驗中，我們分別省略了一種或多種預處理策略，並觀察其對最終結果的影響。透過這種方式，我們可以更好地理解各種預處理策略的重要性，並對其優化程度有更清晰的認識。

這種消融實驗的設計方法是：我們將每個預處理策略作為一個"成分"，然後分別對每個成分進行添加或移除，從而創建出多種不同的數據處理方案。每一種方案都對應一種特定的預處理流程，並將其結果與其他方案進行比較。透過這種方法，我們可以明確地看到每一種預處理策略對結果的影響，並對其進行量化評估。



### Case 1: 降採樣 (Downsampling)
### 文件名: Baseline_Downsample_F6.csv

在這個基準案例中，我們將原始數據經過降採樣處理，將數據的採樣頻率降低。這是最基本的預處理步驟，它的主要目的是降低數據的複雜性和規模，使得後續的分析更易於處理。這也為我們提供了一個基準，可以用來評估其他更複雜的預處理策略的效果。

### Case 2: 正規化+降採樣
### 文件名: Normalization_Downsample_F6.csv

在第二個案例中，我們在降採樣的基礎上加入了正規化步驟。正規化是一種常見的數據預處理方法，它的主要目的是消除數據中的量級差異，使得所有的數據都在同一個量級上，這樣可以避免模型被某些數據的量級差異所影響。

### Case 3: 靜態校正+正規化+降採樣
### 文件名: Correction_Normalization_Downsample_F6.csv

在第三個案例中，我們在正規化和降採樣的基礎上進行了靜態校正。靜態校正的目的是糾正數據中可能存在的靜態偏差，例如由於儀器的校準問題等引起的偏差。

### Case 4: 卡爾曼濾波器+正規化+降採樣
### 文件名: Kalman_Normalization_Downsample_F6.csv

在第四個案例中，我們引入了卡爾曼濾波器進行數據處理。卡爾曼濾波器是一種優秀的時間序列數據處理工具，能夠有效地處理數據中的雜訊並提取出數據的真實變化趨勢。

### Case 5: 靜態校正+卡爾曼濾波器+正規化+降採樣
### 文件名: Correction_Kalman_Normalization_Downsample_F6.csv

在第五個案例中，我們將所有的預處理步驟都結合起來，包括靜態校正、卡爾曼濾波器、正規化和降採樣。這種組合允許我們看到當所有的預處理步驟都使用時，對最終結果的影響。

### Case 6: 靜態校正+正規化+卡爾曼濾波器+降採樣
### 文件名: Correction_Normalization_Kalman_Downsample_F6.csv

在第六個案例中，我們改變了預處理步驟的順序。這個案例的目的是探討預處理步驟的順序對最終結果的影響。

透過這六種不同的數據處理方案，我們能夠深入理解每個預處理步驟對最終結果的影響，這對於優化數據處理流程，提高最終分析結果的準確性和可靠性具有關鍵的指導意義。在沒有真實的分群標籤的情況下，我們將分群完的結果拿去訓練變量長度馬可夫模型(VLMM)，以模型的預測準確度來評價分群的效果。






# 4.2 特徵工程與主成分分析(PCA)
特徵工程與主成分分析（PCA）在我們的機車儀器測量單元 (IMU) 和引擎控制單元 (ECU) 數據分析中扮演了重要的角色。在這一章節中，我們會詳細介紹我們如何透過這兩種技術，挑選出對模型最具影響力的特徵，以及如何透過PCA降低數據維度以優化我們的模型表現。

## 4.2.1 特徵工程和主成分分析 (PCA)
特徵工程的目標是找出最具代表性的數據特徵，並根據這些特徵來訓練我們的機器學習模型。這可能涉及到特徵的挑選，或者透過降維技術，如PCA，來降低數據的複雜度。

PCA是一種常用的降維技術，它尋找一組新的特徵，這些特徵是原始數據特徵的線性組合，並且這些新的特徵，即主成分，能夠最大化數據的方差。在我們的應用中，我們透過觀察解釋方差比來確定需要保留多少主成分。在大多數情況下，我們希望至少保留95%的方差，以確保在降低數據複雜度的同時，仍然保留大部分的數據信息。

每個主成分都是原始特徵的線性組合，並且每個原始特徵在這個線性組合中的權重代表了該特徵在該主成分中的重要性。我們可以透過將每個原始特徵在所有主成分中的權重加總，來獲得該特徵的總權重，從而評估該特徵的重要性。

## 4.2.2 特徵工程消融實驗 (IMU)
為了更好地理解我們的特徵選擇和降維策略對模型性能的影響，我們對IMU數據進行了以下消融實驗：

### Case 1：僅使用IMU的9個特徵：這是我們的基線實驗，我們將在這個基線的基礎上進行比較。我們使用預處理後的IMU數據，不進行任何特徵選擇或降維操作。

### Case 2：使用IMU並通過PCA降至k個特徵：在這個實驗中，我們對IMU數據進行PCA，並選擇前k個主成分作為我們的特徵。我們將比較不同的k值對模型性能的影響，並試圖找到一個平衡點，在保留足夠的數據信息的同時，減少數據的維度和模型的複雜度。

### Case 3：僅使用IMU中最重要的k個特徵：在這個實驗中，我們將只使用最重要的k個特徵來訓練我們的模型。我們會使用PCA的結果來評估特徵的重要性，並選擇權重最大的k個特徵。另外，我們也會使用隨機森林的特徵重要性作為一個比較，看看兩種方法是否有一致的結果。

### Case 4：使用IMU並通過PCA降至3個特徵：在這個實驗中，我們再次使用PCA，但是這次我們只保留前3個主成分。我們將這個結果與Case 2進行比較，看看進一步降低數據維度是否會對模型性能產生顯著影響。

以上的實驗設計讓我們可以全面地理解特徵選擇和降維策略對模型性能的影響，並幫助我們優化我們的特徵工程策略。



## 4.2.3 特徵工程消融實驗：IMU+ECU

在此階段的實驗中，我們嘗試深入探索並比較三種不同的特徵選擇策略對模型性能的影響。此實驗不僅考慮了來自IMU的資料，還將引擎控制單元 (ECU) 的特徵資料納入考量，提供更完整與全面的數據視角。

### Case 1：使用IMU與ECU的38個特徵 (Baseline):
在此實驗中，我們使用了所有可用的38個特徵，包含IMU與ECU的所有數據，作為我們的基準模型（Baseline）。我們並未對特徵進行任何選擇或篩選，旨在觀察所有特徵整體對模型性能的影響。

### Case 2：使用IMU與ECU並通過PCA降至k個特徵:
在此實驗中，我們將IMU與ECU的數據進行合併，然後利用主成分分析 (PCA) 降維，篩選出k個最主要的特徵。我們也使用隨機森林（Random Forest）的平均劃分減少和平均覆蓋度減少來進行特徵重要性評估，並挑選出最重要的k個特徵。

### Case 3：使用IMU通過PCA降至k個特徵 + 使用ECU通過PCA降至k個特徵:
在此實驗中，我們分別對IMU與ECU的數據進行主成分分析 (PCA) 降維，然後各自篩選出k個最主要的特徵。此外，我們也針對IMU和ECU各自的數據使用隨機森林的平均劃分減少和平均覆蓋度減少方法，分別選出重要性最高的k個特徵。

實驗結果分析:

在完成以上各階段的實驗後，我們將深入研究各種預處理和特徵選擇策略對模型性能的影響。我們將比較每種策略的實驗結果，從中找出對模型預測準確度提升幅度最大的策略。這將有助於我們在實際應用中，有效地提升模型的性能並優化預測結果。



